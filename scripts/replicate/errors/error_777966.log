++ export VLLM_ATTENTION_BACKEND=XFORMERS
++ VLLM_ATTENTION_BACKEND=XFORMERS
++ MODEL_PATH=/home/bingxing2/ailab/wangkuncan/soft/l1/DeepScaleR-1.5B-Preview
++ NUM_TOKENS=512
++ MAX_TOKENS=1024
++ DATATYPES=("gpqa" "mmlu_1000" "lsat" "aime2025" "math" "amc" "aime" "olympiad_bench")
++ OUTPUT_DIR='$/home/bingxing2/ailab/wangkuncan/soft/l1'
++ [[ 8 -gt 0 ]]
++ case $1 in
++ MODEL_PATH=l3lab/L1-Qwen-1.5B-Exact
++ shift 2
++ [[ 6 -gt 0 ]]
++ case $1 in
++ NUM_TOKENS=512
++ MAX_TOKENS=1024
++ shift 2
++ [[ 4 -gt 0 ]]
++ case $1 in
++ shift
++ DATATYPES=()
++ [[ 3 -gt 0 ]]
++ [[ ! aime =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 2 -gt 0 ]]
++ [[ ! mmlu_1000 =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 1 -gt 0 ]]
++ [[ ! lsat =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 0 -gt 0 ]]
++ [[ 0 -gt 0 ]]
++ echo 'Model Path: l3lab/L1-Qwen-1.5B-Exact'
++ echo 'Datasets: aime' mmlu_1000 lsat
++ echo 'Output Directory: $/home/bingxing2/ailab/wangkuncan/soft/l1'
++ echo 'Number of Tokens: 512'
++ echo 'Max Tokens: 1024'
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_512/aime.parquet 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_512/aime.parquet' data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=1024 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
2025-04-29 16:16:45,661	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=371491)[0m Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745917985&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxNzk4NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=GdQ4B0fU%7EcugbDjDjz5cV0YE48m4XbiF9td%7EnRxN50esAnLbCQ0RK2OrRXIjKLtkyH8PKm4FctG-PQXhOv6Otl304gFmzsfJArHE86N6jrTje3yqzsn8pSFJrB6GXiEjRNzR-8YY8l9uFVyBjjQ-i%7E7KEN1GL6l6VTBqSVwSvIXSGsBdivPbJkgRF%7E%7EUtZVuP9Lef0y5bR9G8F5I%7E-MS3Tq9VErOWm4GI3vNl%7EHbQj5RYEdYhHZOhPC913VUUxKnNyOOq2y%7E20aDD9Xl3ge96aGQvOGfJ3aq7ZkF357hVGM0ckNtpcKDQPaRGcyySAkc1maLhDrHg1UPmKZVi1%7ED9w__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=371491)[0m Trying to resume download...
[36m(main_task pid=371491)[0m WARNING:2025-04-29 16:17:53,949:Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745917985&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxNzk4NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=GdQ4B0fU%7EcugbDjDjz5cV0YE48m4XbiF9td%7EnRxN50esAnLbCQ0RK2OrRXIjKLtkyH8PKm4FctG-PQXhOv6Otl304gFmzsfJArHE86N6jrTje3yqzsn8pSFJrB6GXiEjRNzR-8YY8l9uFVyBjjQ-i%7E7KEN1GL6l6VTBqSVwSvIXSGsBdivPbJkgRF%7E%7EUtZVuP9Lef0y5bR9G8F5I%7E-MS3Tq9VErOWm4GI3vNl%7EHbQj5RYEdYhHZOhPC913VUUxKnNyOOq2y%7E20aDD9Xl3ge96aGQvOGfJ3aq7ZkF357hVGM0ckNtpcKDQPaRGcyySAkc1maLhDrHg1UPmKZVi1%7ED9w__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=371491)[0m Trying to resume download...
[36m(main_task pid=371491)[0m Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745917985&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxNzk4NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=GdQ4B0fU%7EcugbDjDjz5cV0YE48m4XbiF9td%7EnRxN50esAnLbCQ0RK2OrRXIjKLtkyH8PKm4FctG-PQXhOv6Otl304gFmzsfJArHE86N6jrTje3yqzsn8pSFJrB6GXiEjRNzR-8YY8l9uFVyBjjQ-i%7E7KEN1GL6l6VTBqSVwSvIXSGsBdivPbJkgRF%7E%7EUtZVuP9Lef0y5bR9G8F5I%7E-MS3Tq9VErOWm4GI3vNl%7EHbQj5RYEdYhHZOhPC913VUUxKnNyOOq2y%7E20aDD9Xl3ge96aGQvOGfJ3aq7ZkF357hVGM0ckNtpcKDQPaRGcyySAkc1maLhDrHg1UPmKZVi1%7ED9w__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=371491)[0m Trying to resume download...
[36m(main_task pid=371491)[0m WARNING:2025-04-29 16:18:19,897:Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745917985&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxNzk4NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=GdQ4B0fU%7EcugbDjDjz5cV0YE48m4XbiF9td%7EnRxN50esAnLbCQ0RK2OrRXIjKLtkyH8PKm4FctG-PQXhOv6Otl304gFmzsfJArHE86N6jrTje3yqzsn8pSFJrB6GXiEjRNzR-8YY8l9uFVyBjjQ-i%7E7KEN1GL6l6VTBqSVwSvIXSGsBdivPbJkgRF%7E%7EUtZVuP9Lef0y5bR9G8F5I%7E-MS3Tq9VErOWm4GI3vNl%7EHbQj5RYEdYhHZOhPC913VUUxKnNyOOq2y%7E20aDD9Xl3ge96aGQvOGfJ3aq7ZkF357hVGM0ckNtpcKDQPaRGcyySAkc1maLhDrHg1UPmKZVi1%7ED9w__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=371491)[0m Trying to resume download...
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_512/aime.parquet', 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_512/aime.parquet', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=l3lab/L1-Qwen-1.5B-Exact', 'rollout.temperature=0.6', 'rollout.response_length=1024', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.9', 'rollout.tensor_model_parallel_size=1']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 41, in main
    run_generation(config)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 50, in run_generation
    ray.get(main_task.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TypeError): [36mray::main_task()[39m (pid=371491, ip=173.3.164.136)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 61, in main_task
    tokenizer = hf_tokenizer(local_path)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/utils/tokenizer.py", line 56, in hf_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(name_or_path, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 1009, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2062, in from_pretrained
    return cls._from_pretrained(
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2100, in _from_pretrained
    slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2302, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py", line 169, in __init__
    self.sp_model = self.get_spm_processor(kwargs.pop("from_slow", False))
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py", line 196, in get_spm_processor
    tokenizer.Load(self.vocab_file)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/sentencepiece/__init__.py", line 961, in Load
    return self.LoadFromFile(model_file)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/sentencepiece/__init__.py", line 316, in LoadFromFile
    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)
TypeError: not a string

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_512/mmlu_1000.parquet 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_512/mmlu_1000.parquet' data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=1024 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
2025-04-29 16:18:48,952	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=388263)[0m Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918348&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODM0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Xnyego-5iFneXlaZkZY4FogUO3%7Edhr%7E9nBjwcFNDn7P-TthONYRCYyK1bLVYyT3kZPxn1TQrP0-NgFJ4xQjLPkNeV33mQd6l4k-Jmved4ZLZfFLYcCy3zuxzLOciWQUQvjMsDb11KpGlKAf2y5jcNU3WX2oWXeUrThZtuBfY618-xEtc4EDju1SJv6exHIrHPKlM7xrW7qLsSRpO6hgwq9C3JWuCiMLPi2lYf98sbM8E0y5mUC2Ty2bYU0O4wktMrdRQkM9%7EStTUA-fg31p5-VFCe8UBYqvGRRPuCv1dimmtEXJf5AYazM21oro6oTmWVTXH70kNXssplXLPh00VGg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=388263)[0m Trying to resume download...
[36m(main_task pid=388263)[0m WARNING:2025-04-29 16:20:19,187:Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918348&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODM0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Xnyego-5iFneXlaZkZY4FogUO3%7Edhr%7E9nBjwcFNDn7P-TthONYRCYyK1bLVYyT3kZPxn1TQrP0-NgFJ4xQjLPkNeV33mQd6l4k-Jmved4ZLZfFLYcCy3zuxzLOciWQUQvjMsDb11KpGlKAf2y5jcNU3WX2oWXeUrThZtuBfY618-xEtc4EDju1SJv6exHIrHPKlM7xrW7qLsSRpO6hgwq9C3JWuCiMLPi2lYf98sbM8E0y5mUC2Ty2bYU0O4wktMrdRQkM9%7EStTUA-fg31p5-VFCe8UBYqvGRRPuCv1dimmtEXJf5AYazM21oro6oTmWVTXH70kNXssplXLPh00VGg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=388263)[0m Trying to resume download...
[36m(main_task pid=388263)[0m Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918348&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODM0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Xnyego-5iFneXlaZkZY4FogUO3%7Edhr%7E9nBjwcFNDn7P-TthONYRCYyK1bLVYyT3kZPxn1TQrP0-NgFJ4xQjLPkNeV33mQd6l4k-Jmved4ZLZfFLYcCy3zuxzLOciWQUQvjMsDb11KpGlKAf2y5jcNU3WX2oWXeUrThZtuBfY618-xEtc4EDju1SJv6exHIrHPKlM7xrW7qLsSRpO6hgwq9C3JWuCiMLPi2lYf98sbM8E0y5mUC2Ty2bYU0O4wktMrdRQkM9%7EStTUA-fg31p5-VFCe8UBYqvGRRPuCv1dimmtEXJf5AYazM21oro6oTmWVTXH70kNXssplXLPh00VGg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=388263)[0m Trying to resume download...
[36m(main_task pid=388263)[0m WARNING:2025-04-29 16:20:47,081:Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918348&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODM0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Xnyego-5iFneXlaZkZY4FogUO3%7Edhr%7E9nBjwcFNDn7P-TthONYRCYyK1bLVYyT3kZPxn1TQrP0-NgFJ4xQjLPkNeV33mQd6l4k-Jmved4ZLZfFLYcCy3zuxzLOciWQUQvjMsDb11KpGlKAf2y5jcNU3WX2oWXeUrThZtuBfY618-xEtc4EDju1SJv6exHIrHPKlM7xrW7qLsSRpO6hgwq9C3JWuCiMLPi2lYf98sbM8E0y5mUC2Ty2bYU0O4wktMrdRQkM9%7EStTUA-fg31p5-VFCe8UBYqvGRRPuCv1dimmtEXJf5AYazM21oro6oTmWVTXH70kNXssplXLPh00VGg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=388263)[0m Trying to resume download...
[36m(main_task pid=388263)[0m Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918348&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODM0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Xnyego-5iFneXlaZkZY4FogUO3%7Edhr%7E9nBjwcFNDn7P-TthONYRCYyK1bLVYyT3kZPxn1TQrP0-NgFJ4xQjLPkNeV33mQd6l4k-Jmved4ZLZfFLYcCy3zuxzLOciWQUQvjMsDb11KpGlKAf2y5jcNU3WX2oWXeUrThZtuBfY618-xEtc4EDju1SJv6exHIrHPKlM7xrW7qLsSRpO6hgwq9C3JWuCiMLPi2lYf98sbM8E0y5mUC2Ty2bYU0O4wktMrdRQkM9%7EStTUA-fg31p5-VFCe8UBYqvGRRPuCv1dimmtEXJf5AYazM21oro6oTmWVTXH70kNXssplXLPh00VGg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=388263)[0m Trying to resume download...
[36m(main_task pid=388263)[0m WARNING:2025-04-29 16:21:27,450:Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918348&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODM0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Xnyego-5iFneXlaZkZY4FogUO3%7Edhr%7E9nBjwcFNDn7P-TthONYRCYyK1bLVYyT3kZPxn1TQrP0-NgFJ4xQjLPkNeV33mQd6l4k-Jmved4ZLZfFLYcCy3zuxzLOciWQUQvjMsDb11KpGlKAf2y5jcNU3WX2oWXeUrThZtuBfY618-xEtc4EDju1SJv6exHIrHPKlM7xrW7qLsSRpO6hgwq9C3JWuCiMLPi2lYf98sbM8E0y5mUC2Ty2bYU0O4wktMrdRQkM9%7EStTUA-fg31p5-VFCe8UBYqvGRRPuCv1dimmtEXJf5AYazM21oro6oTmWVTXH70kNXssplXLPh00VGg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=388263)[0m Trying to resume download...
[36m(main_task pid=388263)[0m Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918348&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODM0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Xnyego-5iFneXlaZkZY4FogUO3%7Edhr%7E9nBjwcFNDn7P-TthONYRCYyK1bLVYyT3kZPxn1TQrP0-NgFJ4xQjLPkNeV33mQd6l4k-Jmved4ZLZfFLYcCy3zuxzLOciWQUQvjMsDb11KpGlKAf2y5jcNU3WX2oWXeUrThZtuBfY618-xEtc4EDju1SJv6exHIrHPKlM7xrW7qLsSRpO6hgwq9C3JWuCiMLPi2lYf98sbM8E0y5mUC2Ty2bYU0O4wktMrdRQkM9%7EStTUA-fg31p5-VFCe8UBYqvGRRPuCv1dimmtEXJf5AYazM21oro6oTmWVTXH70kNXssplXLPh00VGg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=388263)[0m Trying to resume download...
[36m(main_task pid=388263)[0m WARNING:2025-04-29 16:21:58,405:Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918348&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODM0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Xnyego-5iFneXlaZkZY4FogUO3%7Edhr%7E9nBjwcFNDn7P-TthONYRCYyK1bLVYyT3kZPxn1TQrP0-NgFJ4xQjLPkNeV33mQd6l4k-Jmved4ZLZfFLYcCy3zuxzLOciWQUQvjMsDb11KpGlKAf2y5jcNU3WX2oWXeUrThZtuBfY618-xEtc4EDju1SJv6exHIrHPKlM7xrW7qLsSRpO6hgwq9C3JWuCiMLPi2lYf98sbM8E0y5mUC2Ty2bYU0O4wktMrdRQkM9%7EStTUA-fg31p5-VFCe8UBYqvGRRPuCv1dimmtEXJf5AYazM21oro6oTmWVTXH70kNXssplXLPh00VGg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=388263)[0m Trying to resume download...
[36m(main_task pid=388263)[0m Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918348&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODM0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Xnyego-5iFneXlaZkZY4FogUO3%7Edhr%7E9nBjwcFNDn7P-TthONYRCYyK1bLVYyT3kZPxn1TQrP0-NgFJ4xQjLPkNeV33mQd6l4k-Jmved4ZLZfFLYcCy3zuxzLOciWQUQvjMsDb11KpGlKAf2y5jcNU3WX2oWXeUrThZtuBfY618-xEtc4EDju1SJv6exHIrHPKlM7xrW7qLsSRpO6hgwq9C3JWuCiMLPi2lYf98sbM8E0y5mUC2Ty2bYU0O4wktMrdRQkM9%7EStTUA-fg31p5-VFCe8UBYqvGRRPuCv1dimmtEXJf5AYazM21oro6oTmWVTXH70kNXssplXLPh00VGg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=388263)[0m Trying to resume download...
[36m(main_task pid=388263)[0m WARNING:2025-04-29 16:22:52,793:Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918348&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODM0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Xnyego-5iFneXlaZkZY4FogUO3%7Edhr%7E9nBjwcFNDn7P-TthONYRCYyK1bLVYyT3kZPxn1TQrP0-NgFJ4xQjLPkNeV33mQd6l4k-Jmved4ZLZfFLYcCy3zuxzLOciWQUQvjMsDb11KpGlKAf2y5jcNU3WX2oWXeUrThZtuBfY618-xEtc4EDju1SJv6exHIrHPKlM7xrW7qLsSRpO6hgwq9C3JWuCiMLPi2lYf98sbM8E0y5mUC2Ty2bYU0O4wktMrdRQkM9%7EStTUA-fg31p5-VFCe8UBYqvGRRPuCv1dimmtEXJf5AYazM21oro6oTmWVTXH70kNXssplXLPh00VGg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=388263)[0m Trying to resume download...
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_512/mmlu_1000.parquet', 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_512/mmlu_1000.parquet', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=l3lab/L1-Qwen-1.5B-Exact', 'rollout.temperature=0.6', 'rollout.response_length=1024', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.9', 'rollout.tensor_model_parallel_size=1']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 41, in main
    run_generation(config)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 50, in run_generation
    ray.get(main_task.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TypeError): [36mray::main_task()[39m (pid=388263, ip=173.3.164.136)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 61, in main_task
    tokenizer = hf_tokenizer(local_path)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/utils/tokenizer.py", line 56, in hf_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(name_or_path, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 1009, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2062, in from_pretrained
    return cls._from_pretrained(
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2100, in _from_pretrained
    slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2302, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py", line 169, in __init__
    self.sp_model = self.get_spm_processor(kwargs.pop("from_slow", False))
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py", line 196, in get_spm_processor
    tokenizer.Load(self.vocab_file)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/sentencepiece/__init__.py", line 961, in Load
    return self.LoadFromFile(model_file)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/sentencepiece/__init__.py", line 316, in LoadFromFile
    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)
TypeError: not a string

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_512/lsat.parquet 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_512/lsat.parquet' data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=1024 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
2025-04-29 16:23:23,450	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=411208)[0m Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918624&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODYyNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=q%7EjyIGbgTMT6Sa%7ECe-iYiJoO5BP3wlPE5m9-cQBj4z96%7EXzqU3kWM1n8aFB1RiPY28mItK%7EVNHDI2uy7e3i-6D7yGQNAWeHrHtsxW22h0L0w0h-C%7EFzV9oxzNyWDmoTDvjKHW7jB6R7lakopxsMpefOoUXT6YfkKdMcIn%7EvUflyvlgfKW7MfhWRJiQN%7EiengcIuEYiRGXhj2bA-6misFKVDKmAHeEWtHgAsImRFIOkmAsiXpZJ-6MqxDy%7EiuTvNnFwzvq61SV3Nt2lQ1KVB14K9RVlRm1FiVxUeUVorg0dz2BTeZeAkI2L9QCF6fFmkkNkCbeNSL%7Es6aUIh%7Ezyzznw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=411208)[0m Trying to resume download...
[36m(main_task pid=411208)[0m WARNING:2025-04-29 16:25:12,140:Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918624&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODYyNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=q%7EjyIGbgTMT6Sa%7ECe-iYiJoO5BP3wlPE5m9-cQBj4z96%7EXzqU3kWM1n8aFB1RiPY28mItK%7EVNHDI2uy7e3i-6D7yGQNAWeHrHtsxW22h0L0w0h-C%7EFzV9oxzNyWDmoTDvjKHW7jB6R7lakopxsMpefOoUXT6YfkKdMcIn%7EvUflyvlgfKW7MfhWRJiQN%7EiengcIuEYiRGXhj2bA-6misFKVDKmAHeEWtHgAsImRFIOkmAsiXpZJ-6MqxDy%7EiuTvNnFwzvq61SV3Nt2lQ1KVB14K9RVlRm1FiVxUeUVorg0dz2BTeZeAkI2L9QCF6fFmkkNkCbeNSL%7Es6aUIh%7Ezyzznw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=411208)[0m Trying to resume download...
[36m(main_task pid=411208)[0m Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918624&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODYyNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=q%7EjyIGbgTMT6Sa%7ECe-iYiJoO5BP3wlPE5m9-cQBj4z96%7EXzqU3kWM1n8aFB1RiPY28mItK%7EVNHDI2uy7e3i-6D7yGQNAWeHrHtsxW22h0L0w0h-C%7EFzV9oxzNyWDmoTDvjKHW7jB6R7lakopxsMpefOoUXT6YfkKdMcIn%7EvUflyvlgfKW7MfhWRJiQN%7EiengcIuEYiRGXhj2bA-6misFKVDKmAHeEWtHgAsImRFIOkmAsiXpZJ-6MqxDy%7EiuTvNnFwzvq61SV3Nt2lQ1KVB14K9RVlRm1FiVxUeUVorg0dz2BTeZeAkI2L9QCF6fFmkkNkCbeNSL%7Es6aUIh%7Ezyzznw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=411208)[0m Trying to resume download...
[36m(main_task pid=411208)[0m WARNING:2025-04-29 16:25:47,105:Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918624&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODYyNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=q%7EjyIGbgTMT6Sa%7ECe-iYiJoO5BP3wlPE5m9-cQBj4z96%7EXzqU3kWM1n8aFB1RiPY28mItK%7EVNHDI2uy7e3i-6D7yGQNAWeHrHtsxW22h0L0w0h-C%7EFzV9oxzNyWDmoTDvjKHW7jB6R7lakopxsMpefOoUXT6YfkKdMcIn%7EvUflyvlgfKW7MfhWRJiQN%7EiengcIuEYiRGXhj2bA-6misFKVDKmAHeEWtHgAsImRFIOkmAsiXpZJ-6MqxDy%7EiuTvNnFwzvq61SV3Nt2lQ1KVB14K9RVlRm1FiVxUeUVorg0dz2BTeZeAkI2L9QCF6fFmkkNkCbeNSL%7Es6aUIh%7Ezyzznw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=411208)[0m Trying to resume download...
[36m(main_task pid=411208)[0m Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918624&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODYyNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=q%7EjyIGbgTMT6Sa%7ECe-iYiJoO5BP3wlPE5m9-cQBj4z96%7EXzqU3kWM1n8aFB1RiPY28mItK%7EVNHDI2uy7e3i-6D7yGQNAWeHrHtsxW22h0L0w0h-C%7EFzV9oxzNyWDmoTDvjKHW7jB6R7lakopxsMpefOoUXT6YfkKdMcIn%7EvUflyvlgfKW7MfhWRJiQN%7EiengcIuEYiRGXhj2bA-6misFKVDKmAHeEWtHgAsImRFIOkmAsiXpZJ-6MqxDy%7EiuTvNnFwzvq61SV3Nt2lQ1KVB14K9RVlRm1FiVxUeUVorg0dz2BTeZeAkI2L9QCF6fFmkkNkCbeNSL%7Es6aUIh%7Ezyzznw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=411208)[0m Trying to resume download...
[36m(main_task pid=411208)[0m WARNING:2025-04-29 16:27:34,767:Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4f/77/4f77cef2f47b8528d99d579a7d88d620ad5974d294d6842656ff2012df31c010/e20ddafc659ba90242154b55275402edeca0715e5dbb30f56815a4ce081f4893?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tokenizer.json%3B+filename%3D%22tokenizer.json%22%3B&response-content-type=application%2Fjson&Expires=1745918624&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTkxODYyNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzc3LzRmNzdjZWYyZjQ3Yjg1MjhkOTlkNTc5YTdkODhkNjIwYWQ1OTc0ZDI5NGQ2ODQyNjU2ZmYyMDEyZGYzMWMwMTAvZTIwZGRhZmM2NTliYTkwMjQyMTU0YjU1Mjc1NDAyZWRlY2EwNzE1ZTVkYmIzMGY1NjgxNWE0Y2UwODFmNDg5Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=q%7EjyIGbgTMT6Sa%7ECe-iYiJoO5BP3wlPE5m9-cQBj4z96%7EXzqU3kWM1n8aFB1RiPY28mItK%7EVNHDI2uy7e3i-6D7yGQNAWeHrHtsxW22h0L0w0h-C%7EFzV9oxzNyWDmoTDvjKHW7jB6R7lakopxsMpefOoUXT6YfkKdMcIn%7EvUflyvlgfKW7MfhWRJiQN%7EiengcIuEYiRGXhj2bA-6misFKVDKmAHeEWtHgAsImRFIOkmAsiXpZJ-6MqxDy%7EiuTvNnFwzvq61SV3Nt2lQ1KVB14K9RVlRm1FiVxUeUVorg0dz2BTeZeAkI2L9QCF6fFmkkNkCbeNSL%7Es6aUIh%7Ezyzznw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.
[36m(main_task pid=411208)[0m Trying to resume download...
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_512/lsat.parquet', 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_512/lsat.parquet', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=l3lab/L1-Qwen-1.5B-Exact', 'rollout.temperature=0.6', 'rollout.response_length=1024', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.9', 'rollout.tensor_model_parallel_size=1']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 41, in main
    run_generation(config)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 50, in run_generation
    ray.get(main_task.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TypeError): [36mray::main_task()[39m (pid=411208, ip=173.3.164.136)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 61, in main_task
    tokenizer = hf_tokenizer(local_path)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/utils/tokenizer.py", line 56, in hf_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(name_or_path, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 1009, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2062, in from_pretrained
    return cls._from_pretrained(
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2100, in _from_pretrained
    slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2302, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py", line 169, in __init__
    self.sp_model = self.get_spm_processor(kwargs.pop("from_slow", False))
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py", line 196, in get_spm_processor
    tokenizer.Load(self.vocab_file)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/sentencepiece/__init__.py", line 961, in Load
    return self.LoadFromFile(model_file)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/sentencepiece/__init__.py", line 316, in LoadFromFile
    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)
TypeError: not a string

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
++ export VLLM_ATTENTION_BACKEND=XFORMERS
++ VLLM_ATTENTION_BACKEND=XFORMERS
++ MODEL_PATH=/home/bingxing2/ailab/wangkuncan/soft/l1/DeepScaleR-1.5B-Preview
++ NUM_TOKENS=512
++ MAX_TOKENS=1024
++ DATATYPES=("gpqa" "mmlu_1000" "lsat" "aime2025" "math" "amc" "aime" "olympiad_bench")
++ OUTPUT_DIR='$/home/bingxing2/ailab/wangkuncan/soft/l1'
++ [[ 8 -gt 0 ]]
++ case $1 in
++ MODEL_PATH=l3lab/L1-Qwen-1.5B-Exact
++ shift 2
++ [[ 6 -gt 0 ]]
++ case $1 in
++ NUM_TOKENS=1024
++ MAX_TOKENS=2048
++ shift 2
++ [[ 4 -gt 0 ]]
++ case $1 in
++ shift
++ DATATYPES=()
++ [[ 3 -gt 0 ]]
++ [[ ! aime =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 2 -gt 0 ]]
++ [[ ! mmlu_1000 =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 1 -gt 0 ]]
++ [[ ! lsat =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 0 -gt 0 ]]
++ [[ 0 -gt 0 ]]
++ echo 'Model Path: l3lab/L1-Qwen-1.5B-Exact'
++ echo 'Datasets: aime' mmlu_1000 lsat
++ echo 'Output Directory: $/home/bingxing2/ailab/wangkuncan/soft/l1'
++ echo 'Number of Tokens: 1024'
++ echo 'Max Tokens: 2048'
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_1024/aime.parquet 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_1024/aime.parquet' data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=2048 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
2025-04-29 16:28:04,227	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_1024/aime.parquet', 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_1024/aime.parquet', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=l3lab/L1-Qwen-1.5B-Exact', 'rollout.temperature=0.6', 'rollout.response_length=2048', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.9', 'rollout.tensor_model_parallel_size=1']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 41, in main
    run_generation(config)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 50, in run_generation
    ray.get(main_task.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TypeError): [36mray::main_task()[39m (pid=433561, ip=173.3.164.136)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 61, in main_task
    tokenizer = hf_tokenizer(local_path)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/utils/tokenizer.py", line 56, in hf_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(name_or_path, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 1009, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2062, in from_pretrained
    return cls._from_pretrained(
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2100, in _from_pretrained
    slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2302, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py", line 169, in __init__
    self.sp_model = self.get_spm_processor(kwargs.pop("from_slow", False))
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py", line 196, in get_spm_processor
    tokenizer.Load(self.vocab_file)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/sentencepiece/__init__.py", line 961, in Load
    return self.LoadFromFile(model_file)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/sentencepiece/__init__.py", line 316, in LoadFromFile
    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)
TypeError: not a string

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_1024/mmlu_1000.parquet 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_1024/mmlu_1000.parquet' data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=2048 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
2025-04-29 16:28:59,364	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_1024/mmlu_1000.parquet', 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_1024/mmlu_1000.parquet', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=l3lab/L1-Qwen-1.5B-Exact', 'rollout.temperature=0.6', 'rollout.response_length=2048', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.9', 'rollout.tensor_model_parallel_size=1']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 41, in main
    run_generation(config)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 50, in run_generation
    ray.get(main_task.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TypeError): [36mray::main_task()[39m (pid=447870, ip=173.3.164.136)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 61, in main_task
    tokenizer = hf_tokenizer(local_path)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/utils/tokenizer.py", line 56, in hf_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(name_or_path, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 1009, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2062, in from_pretrained
    return cls._from_pretrained(
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2100, in _from_pretrained
    slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2302, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py", line 169, in __init__
    self.sp_model = self.get_spm_processor(kwargs.pop("from_slow", False))
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py", line 196, in get_spm_processor
    tokenizer.Load(self.vocab_file)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/sentencepiece/__init__.py", line 961, in Load
    return self.LoadFromFile(model_file)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/sentencepiece/__init__.py", line 316, in LoadFromFile
    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)
TypeError: not a string

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_1024/lsat.parquet 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_1024/lsat.parquet' data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=2048 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
2025-04-29 16:29:57,574	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_1024/lsat.parquet', 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_1024/lsat.parquet', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=l3lab/L1-Qwen-1.5B-Exact', 'rollout.temperature=0.6', 'rollout.response_length=2048', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.9', 'rollout.tensor_model_parallel_size=1']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 41, in main
    run_generation(config)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 50, in run_generation
    ray.get(main_task.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(FileNotFoundError): [36mray::main_task()[39m (pid=461165, ip=173.3.164.136)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 67, in main_task
    dataset = pd.read_parquet(config.data.path)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 667, in read_parquet
    return impl.read(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 267, in read
    path_or_handle, handles, filesystem = _get_path_or_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 140, in _get_path_or_handle
    handles = get_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/home/bingxing2/ailab/wangkuncan/deepscaler/data_1024/lsat.parquet'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
++ export VLLM_ATTENTION_BACKEND=XFORMERS
++ VLLM_ATTENTION_BACKEND=XFORMERS
++ MODEL_PATH=/home/bingxing2/ailab/wangkuncan/soft/l1/DeepScaleR-1.5B-Preview
++ NUM_TOKENS=512
++ MAX_TOKENS=1024
++ DATATYPES=("gpqa" "mmlu_1000" "lsat" "aime2025" "math" "amc" "aime" "olympiad_bench")
++ OUTPUT_DIR='$/home/bingxing2/ailab/wangkuncan/soft/l1'
++ [[ 8 -gt 0 ]]
++ case $1 in
++ MODEL_PATH=l3lab/L1-Qwen-1.5B-Exact
++ shift 2
++ [[ 6 -gt 0 ]]
++ case $1 in
++ NUM_TOKENS=2048
++ MAX_TOKENS=4096
++ shift 2
++ [[ 4 -gt 0 ]]
++ case $1 in
++ shift
++ DATATYPES=()
++ [[ 3 -gt 0 ]]
++ [[ ! aime =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 2 -gt 0 ]]
++ [[ ! mmlu_1000 =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 1 -gt 0 ]]
++ [[ ! lsat =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 0 -gt 0 ]]
++ [[ 0 -gt 0 ]]
++ echo 'Model Path: l3lab/L1-Qwen-1.5B-Exact'
++ echo 'Datasets: aime' mmlu_1000 lsat
++ echo 'Output Directory: $/home/bingxing2/ailab/wangkuncan/soft/l1'
++ echo 'Number of Tokens: 2048'
++ echo 'Max Tokens: 4096'
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/aime.parquet 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_2048/aime.parquet' data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=4096 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
2025-04-29 16:32:31,054	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/aime.parquet', 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_2048/aime.parquet', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=l3lab/L1-Qwen-1.5B-Exact', 'rollout.temperature=0.6', 'rollout.response_length=4096', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.9', 'rollout.tensor_model_parallel_size=1']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 41, in main
    run_generation(config)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 50, in run_generation
    ray.get(main_task.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(FileNotFoundError): [36mray::main_task()[39m (pid=479463, ip=173.3.164.136)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 67, in main_task
    dataset = pd.read_parquet(config.data.path)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 667, in read_parquet
    return impl.read(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 267, in read
    path_or_handle, handles, filesystem = _get_path_or_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 140, in _get_path_or_handle
    handles = get_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/aime.parquet'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/mmlu_1000.parquet 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_2048/mmlu_1000.parquet' data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=4096 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
2025-04-29 16:33:09,687	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/mmlu_1000.parquet', 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_2048/mmlu_1000.parquet', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=l3lab/L1-Qwen-1.5B-Exact', 'rollout.temperature=0.6', 'rollout.response_length=4096', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.9', 'rollout.tensor_model_parallel_size=1']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 41, in main
    run_generation(config)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 50, in run_generation
    ray.get(main_task.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(FileNotFoundError): [36mray::main_task()[39m (pid=493520, ip=173.3.164.136)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 67, in main_task
    dataset = pd.read_parquet(config.data.path)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 667, in read_parquet
    return impl.read(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 267, in read
    path_or_handle, handles, filesystem = _get_path_or_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 140, in _get_path_or_handle
    handles = get_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/mmlu_1000.parquet'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/lsat.parquet 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_2048/lsat.parquet' data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=4096 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
2025-04-29 16:33:48,673	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/lsat.parquet', 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_2048/lsat.parquet', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=l3lab/L1-Qwen-1.5B-Exact', 'rollout.temperature=0.6', 'rollout.response_length=4096', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.9', 'rollout.tensor_model_parallel_size=1']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 41, in main
    run_generation(config)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 50, in run_generation
    ray.get(main_task.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(FileNotFoundError): [36mray::main_task()[39m (pid=506400, ip=173.3.164.136)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 67, in main_task
    dataset = pd.read_parquet(config.data.path)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 667, in read_parquet
    return impl.read(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 267, in read
    path_or_handle, handles, filesystem = _get_path_or_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 140, in _get_path_or_handle
    handles = get_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/lsat.parquet'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
++ export VLLM_ATTENTION_BACKEND=XFORMERS
++ VLLM_ATTENTION_BACKEND=XFORMERS
++ MODEL_PATH=/home/bingxing2/ailab/wangkuncan/soft/l1/DeepScaleR-1.5B-Preview
++ NUM_TOKENS=512
++ MAX_TOKENS=1024
++ DATATYPES=("gpqa" "mmlu_1000" "lsat" "aime2025" "math" "amc" "aime" "olympiad_bench")
++ OUTPUT_DIR='$/home/bingxing2/ailab/wangkuncan/soft/l1'
++ [[ 8 -gt 0 ]]
++ case $1 in
++ MODEL_PATH=l3lab/L1-Qwen-1.5B-Exact
++ shift 2
++ [[ 6 -gt 0 ]]
++ case $1 in
++ NUM_TOKENS=3600
++ MAX_TOKENS=7200
++ shift 2
++ [[ 4 -gt 0 ]]
++ case $1 in
++ shift
++ DATATYPES=()
++ [[ 3 -gt 0 ]]
++ [[ ! aime =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 2 -gt 0 ]]
++ [[ ! mmlu_1000 =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 1 -gt 0 ]]
++ [[ ! lsat =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 0 -gt 0 ]]
++ [[ 0 -gt 0 ]]
++ echo 'Model Path: l3lab/L1-Qwen-1.5B-Exact'
++ echo 'Datasets: aime' mmlu_1000 lsat
++ echo 'Output Directory: $/home/bingxing2/ailab/wangkuncan/soft/l1'
++ echo 'Number of Tokens: 3600'
++ echo 'Max Tokens: 7200'
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/aime.parquet 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_3600/aime.parquet' data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=7200 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
2025-04-29 16:34:24,456	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/aime.parquet', 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_3600/aime.parquet', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=l3lab/L1-Qwen-1.5B-Exact', 'rollout.temperature=0.6', 'rollout.response_length=7200', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.9', 'rollout.tensor_model_parallel_size=1']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 41, in main
    run_generation(config)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 50, in run_generation
    ray.get(main_task.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(FileNotFoundError): [36mray::main_task()[39m (pid=520188, ip=173.3.164.136)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 67, in main_task
    dataset = pd.read_parquet(config.data.path)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 667, in read_parquet
    return impl.read(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 267, in read
    path_or_handle, handles, filesystem = _get_path_or_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 140, in _get_path_or_handle
    handles = get_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/aime.parquet'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/mmlu_1000.parquet 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_3600/mmlu_1000.parquet' data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=7200 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
2025-04-29 16:35:10,047	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/mmlu_1000.parquet', 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_3600/mmlu_1000.parquet', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=l3lab/L1-Qwen-1.5B-Exact', 'rollout.temperature=0.6', 'rollout.response_length=7200', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.9', 'rollout.tensor_model_parallel_size=1']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 41, in main
    run_generation(config)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 50, in run_generation
    ray.get(main_task.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(FileNotFoundError): [36mray::main_task()[39m (pid=534383, ip=173.3.164.136)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 67, in main_task
    dataset = pd.read_parquet(config.data.path)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 667, in read_parquet
    return impl.read(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 267, in read
    path_or_handle, handles, filesystem = _get_path_or_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 140, in _get_path_or_handle
    handles = get_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/mmlu_1000.parquet'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/lsat.parquet 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_3600/lsat.parquet' data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=7200 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
2025-04-29 16:35:56,134	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/lsat.parquet', 'data.output_path=$/home/bingxing2/ailab/wangkuncan/soft/l1_3600/lsat.parquet', 'data.n_samples=16', 'data.batch_size=2048', 'model.path=l3lab/L1-Qwen-1.5B-Exact', 'rollout.temperature=0.6', 'rollout.response_length=7200', 'rollout.top_k=-1', 'rollout.top_p=0.95', 'rollout.gpu_memory_utilization=0.9', 'rollout.tensor_model_parallel_size=1']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 41, in main
    run_generation(config)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 50, in run_generation
    ray.get(main_task.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(FileNotFoundError): [36mray::main_task()[39m (pid=547025, ip=173.3.164.136)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/verl/trainer/main_generation.py", line 67, in main_task
    dataset = pd.read_parquet(config.data.path)
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 667, in read_parquet
    return impl.read(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 267, in read
    path_or_handle, handles, filesystem = _get_path_or_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/parquet.py", line 140, in _get_path_or_handle
    handles = get_handle(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/lsat.parquet'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
