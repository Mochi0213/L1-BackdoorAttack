++ export VLLM_ATTENTION_BACKEND=XFORMERS
++ VLLM_ATTENTION_BACKEND=XFORMERS
++ MODEL_PATH=/home/bingxing2/ailab/wangkuncan/DeepScaleR-1.5B-Preview
++ NUM_TOKENS=512
++ MAX_TOKENS=1024
++ DATATYPES=("gpqa" "mmlu_1000" "lsat" "aime2025" "math" "amc" "aime" "olympiad_bench")
++ OUTPUT_DIR=/home/bingxing2/ailab/wangkuncan
++ [[ 9 -gt 0 ]]
++ case $1 in
++ MODEL_PATH=l3lab/L1-Qwen-1.5B-Exact
++ shift 2
++ [[ 7 -gt 0 ]]
++ case $1 in
++ NUM_TOKENS=512
++ MAX_TOKENS=1024
++ shift 2
++ [[ 5 -gt 0 ]]
++ case $1 in
++ shift
++ DATATYPES=()
++ [[ 4 -gt 0 ]]
++ [[ ! aime =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 3 -gt 0 ]]
++ [[ ! gpqa =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 2 -gt 0 ]]
++ [[ ! mmlu_1000 =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 1 -gt 0 ]]
++ [[ ! lsat =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 0 -gt 0 ]]
++ [[ 0 -gt 0 ]]
++ echo 'Model Path: l3lab/L1-Qwen-1.5B-Exact'
++ echo 'Datasets: aime' gpqa mmlu_1000 lsat
++ echo 'Output Directory: /home/bingxing2/ailab/wangkuncan'
++ echo 'Number of Tokens: 512'
++ echo 'Max Tokens: 1024'
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_512/aime.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_512/aime.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=1024 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_512/gpqa.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_512/gpqa.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=1024 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_512/mmlu_1000.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_512/mmlu_1000.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=1024 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_512/lsat.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_512/lsat.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=1024 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ export VLLM_ATTENTION_BACKEND=XFORMERS
++ VLLM_ATTENTION_BACKEND=XFORMERS
++ MODEL_PATH=/home/bingxing2/ailab/wangkuncan/DeepScaleR-1.5B-Preview
++ NUM_TOKENS=512
++ MAX_TOKENS=1024
++ DATATYPES=("gpqa" "mmlu_1000" "lsat" "aime2025" "math" "amc" "aime" "olympiad_bench")
++ OUTPUT_DIR=/home/bingxing2/ailab/wangkuncan
++ [[ 9 -gt 0 ]]
++ case $1 in
++ MODEL_PATH=l3lab/L1-Qwen-1.5B-Exact
++ shift 2
++ [[ 7 -gt 0 ]]
++ case $1 in
++ NUM_TOKENS=1024
++ MAX_TOKENS=2048
++ shift 2
++ [[ 5 -gt 0 ]]
++ case $1 in
++ shift
++ DATATYPES=()
++ [[ 4 -gt 0 ]]
++ [[ ! aime =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 3 -gt 0 ]]
++ [[ ! gpqa =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 2 -gt 0 ]]
++ [[ ! mmlu_1000 =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 1 -gt 0 ]]
++ [[ ! lsat =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 0 -gt 0 ]]
++ [[ 0 -gt 0 ]]
++ echo 'Model Path: l3lab/L1-Qwen-1.5B-Exact'
++ echo 'Datasets: aime' gpqa mmlu_1000 lsat
++ echo 'Output Directory: /home/bingxing2/ailab/wangkuncan'
++ echo 'Number of Tokens: 1024'
++ echo 'Max Tokens: 2048'
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_1024/aime.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_1024/aime.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=2048 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_1024/gpqa.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_1024/gpqa.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=2048 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_1024/mmlu_1000.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_1024/mmlu_1000.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=2048 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_1024/lsat.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_1024/lsat.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=2048 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ export VLLM_ATTENTION_BACKEND=XFORMERS
++ VLLM_ATTENTION_BACKEND=XFORMERS
++ MODEL_PATH=/home/bingxing2/ailab/wangkuncan/DeepScaleR-1.5B-Preview
++ NUM_TOKENS=512
++ MAX_TOKENS=1024
++ DATATYPES=("gpqa" "mmlu_1000" "lsat" "aime2025" "math" "amc" "aime" "olympiad_bench")
++ OUTPUT_DIR=/home/bingxing2/ailab/wangkuncan
++ [[ 9 -gt 0 ]]
++ case $1 in
++ MODEL_PATH=l3lab/L1-Qwen-1.5B-Exact
++ shift 2
++ [[ 7 -gt 0 ]]
++ case $1 in
++ NUM_TOKENS=2048
++ MAX_TOKENS=4096
++ shift 2
++ [[ 5 -gt 0 ]]
++ case $1 in
++ shift
++ DATATYPES=()
++ [[ 4 -gt 0 ]]
++ [[ ! aime =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 3 -gt 0 ]]
++ [[ ! gpqa =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 2 -gt 0 ]]
++ [[ ! mmlu_1000 =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 1 -gt 0 ]]
++ [[ ! lsat =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 0 -gt 0 ]]
++ [[ 0 -gt 0 ]]
++ echo 'Model Path: l3lab/L1-Qwen-1.5B-Exact'
++ echo 'Datasets: aime' gpqa mmlu_1000 lsat
++ echo 'Output Directory: /home/bingxing2/ailab/wangkuncan'
++ echo 'Number of Tokens: 2048'
++ echo 'Max Tokens: 4096'
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/aime.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_2048/aime.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=4096 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/gpqa.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_2048/gpqa.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=4096 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/mmlu_1000.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_2048/mmlu_1000.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=4096 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_2048/lsat.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_2048/lsat.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=4096 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ export VLLM_ATTENTION_BACKEND=XFORMERS
++ VLLM_ATTENTION_BACKEND=XFORMERS
++ MODEL_PATH=/home/bingxing2/ailab/wangkuncan/DeepScaleR-1.5B-Preview
++ NUM_TOKENS=512
++ MAX_TOKENS=1024
++ DATATYPES=("gpqa" "mmlu_1000" "lsat" "aime2025" "math" "amc" "aime" "olympiad_bench")
++ OUTPUT_DIR=/home/bingxing2/ailab/wangkuncan
++ [[ 9 -gt 0 ]]
++ case $1 in
++ MODEL_PATH=l3lab/L1-Qwen-1.5B-Exact
++ shift 2
++ [[ 7 -gt 0 ]]
++ case $1 in
++ NUM_TOKENS=3600
++ MAX_TOKENS=7200
++ shift 2
++ [[ 5 -gt 0 ]]
++ case $1 in
++ shift
++ DATATYPES=()
++ [[ 4 -gt 0 ]]
++ [[ ! aime =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 3 -gt 0 ]]
++ [[ ! gpqa =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 2 -gt 0 ]]
++ [[ ! mmlu_1000 =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 1 -gt 0 ]]
++ [[ ! lsat =~ ^-- ]]
++ DATATYPES+=("$1")
++ shift
++ [[ 0 -gt 0 ]]
++ [[ 0 -gt 0 ]]
++ echo 'Model Path: l3lab/L1-Qwen-1.5B-Exact'
++ echo 'Datasets: aime' gpqa mmlu_1000 lsat
++ echo 'Output Directory: /home/bingxing2/ailab/wangkuncan'
++ echo 'Number of Tokens: 3600'
++ echo 'Max Tokens: 7200'
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/aime.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_3600/aime.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=7200 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/gpqa.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_3600/gpqa.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=7200 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/mmlu_1000.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_3600/mmlu_1000.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=7200 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
++ for DATA_TYPE in "${DATATYPES[@]}"
++ python3 -m verl.trainer.main_generation trainer.nnodes=1 trainer.n_gpus_per_node=8 data.path=/home/bingxing2/ailab/wangkuncan/deepscaler/data_3600/lsat.parquet data.output_path=/home/bingxing2/ailab/wangkuncan_3600/lsat.parquet data.n_samples=16 data.batch_size=2048 model.path=l3lab/L1-Qwen-1.5B-Exact rollout.temperature=0.6 rollout.response_length=7200 rollout.top_k=-1 rollout.top_p=0.95 rollout.gpu_memory_utilization=0.9 rollout.tensor_model_parallel_size=1
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_generation.py", line 36, in <module>
    from verl.workers.fsdp_workers import ActorRolloutRefWorker
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/fsdp_workers.py", line 40, in <module>
    from verl.workers.sharding_manager.fsdp_ulysses import FSDPUlyssesShardingManager
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/workers/sharding_manager/__init__.py", line 30, in <module>
    if is_vllm_available():
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/utils/import_utils.py", line 35, in is_vllm_available
    import vllm
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, DecodingConfig, DeviceConfig,
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/__init__.py", line 3, in <module>
    from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/model_executor/layers/quantization/aqlm.py", line 11, in <module>
    from vllm import _custom_ops as ops
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_custom_ops.py", line 8, in <module>
    from vllm._core_ext import ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/vllm/_core_ext.py", line 182, in <module>
    ScalarType = torch.classes._core_C.ScalarType
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/setup/lib/python3.10/site-packages/torch/_classes.py", line 13, in __getattr__
    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)
RuntimeError: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_
