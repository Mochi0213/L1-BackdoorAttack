+ export VLLM_ATTENTION_BACKEND=XFORMERS
+ VLLM_ATTENTION_BACKEND=XFORMERS
++ pwd
+ export PYTHONPATH=/home/bingxing2/ailab/wangkuncan/soft/l1/scripts/train/../../verl/
+ PYTHONPATH=/home/bingxing2/ailab/wangkuncan/soft/l1/scripts/train/../../verl/
+ export LD_PRELOAD=:/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/scikit_learn.libs/libgomp-d22c30c5.so.1.0.0
+ LD_PRELOAD=:/home/bingxing2/ailab/wangkuncan/.conda/envs/L1/lib/python3.10/site-packages/scikit_learn.libs/libgomp-d22c30c5.so.1.0.0
+ export http_proxy=http://u-cEoRwn:EDvFuZTe@172.16.4.9:3128
+ http_proxy=http://u-cEoRwn:EDvFuZTe@172.16.4.9:3128
+ export https_proxy=http://u-cEoRwn:EDvFuZTe@172.16.4.9:3128
+ https_proxy=http://u-cEoRwn:EDvFuZTe@172.16.4.9:3128
+ [[ 0 -gt 0 ]]
+ '[' -z '' ']'
+ MODEL_PATH=agentica-org/DeepScaleR-1.5B-Preview
++ hostname -I
++ awk '{print $1}'
+ HOST_IP=173.3.199.254
+ sleep 15
+ ray start --head --port=6379 --dashboard-port=8265 --ray-client-server-port=10001 --node-ip-address=173.3.199.254
+ export RAY_RUNTIME_ENV_SKIP_SETUP=1
+ RAY_RUNTIME_ENV_SKIP_SETUP=1
+ export RAY_ADDRESS=ray://173.3.199.254:10001
+ RAY_ADDRESS=ray://173.3.199.254:10001
+ python3 -m verl.trainer.main_ppo --config-name=ppo_trainer.yaml +trainer.ray_head_address=ray://173.3.199.254:10001 algorithm.adv_estimator=grpo data.train_files=/home/bingxing2/ailab/wangkuncan/deepscaler/data/mmlu_1000.parquet data.val_files=/home/bingxing2/ailab/wangkuncan/deepscaler/data/mmlu_1000.parquet data.train_batch_size=128 data.val_batch_size=512 data.max_prompt_length=1024 data.max_response_length=4096 actor_rollout_ref.model.path=agentica-org/DeepScaleR-1.5B-Preview actor_rollout_ref.model.lora_rank=8 actor_rollout_ref.model.lora_alpha=16 'actor_rollout_ref.model.target_modules=[k_proj,v_proj]' actor_rollout_ref.actor.optim.lr=1e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=64 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.ppo_max_token_len_per_gpu=32768 actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0.001 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.ulysses_sequence_parallel_size=1 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=True actor_rollout_ref.rollout.tensor_model_parallel_size=2 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.temperature=0.6 actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=16 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.kl_ctrl.kl_coef=0.001 trainer.critic_warmup=0 'trainer.logger=[console]' trainer.project_name=deepscaler trainer.experiment_name=l1_exact trainer.val_before_train=True trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.save_freq=20 trainer.test_freq=20 trainer.default_hdfs_dir=null trainer.total_epochs=3
2025-05-29 16:39:08,796	INFO worker.py:1554 -- Using address ray://173.3.199.254:10001 set in the environment variable RAY_ADDRESS
2025-05-29 16:39:08,825	INFO client_builder.py:244 -- Passing the following kwargs to ray.init() on the server: log_to_driver
Error executing job with overrides: ['+trainer.ray_head_address=ray://173.3.199.254:10001', 'algorithm.adv_estimator=grpo', 'data.train_files=/home/bingxing2/ailab/wangkuncan/deepscaler/data/mmlu_1000.parquet', 'data.val_files=/home/bingxing2/ailab/wangkuncan/deepscaler/data/mmlu_1000.parquet', 'data.train_batch_size=128', 'data.val_batch_size=512', 'data.max_prompt_length=1024', 'data.max_response_length=4096', 'actor_rollout_ref.model.path=agentica-org/DeepScaleR-1.5B-Preview', 'actor_rollout_ref.model.lora_rank=8', 'actor_rollout_ref.model.lora_alpha=16', 'actor_rollout_ref.model.target_modules=[k_proj,v_proj]', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=64', 'actor_rollout_ref.actor.use_dynamic_bsz=True', 'actor_rollout_ref.actor.ppo_max_token_len_per_gpu=32768', 'actor_rollout_ref.actor.use_kl_loss=True', 'actor_rollout_ref.actor.kl_loss_coef=0.001', 'actor_rollout_ref.actor.kl_loss_type=low_var_kl', 'actor_rollout_ref.actor.ulysses_sequence_parallel_size=1', 'actor_rollout_ref.model.enable_gradient_checkpointing=True', 'actor_rollout_ref.actor.fsdp_config.param_offload=False', 'actor_rollout_ref.actor.fsdp_config.optimizer_offload=True', 'actor_rollout_ref.rollout.tensor_model_parallel_size=2', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.temperature=0.6', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.8', 'actor_rollout_ref.rollout.n=16', 'actor_rollout_ref.ref.fsdp_config.param_offload=True', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.critic_warmup=0', 'trainer.logger=[console]', 'trainer.project_name=deepscaler', 'trainer.experiment_name=l1_exact', 'trainer.val_before_train=True', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=20', 'trainer.test_freq=20', 'trainer.default_hdfs_dir=null', 'trainer.total_epochs=3']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_ppo.py", line 64, in main
    run_ppo(config)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_ppo.py", line 70, in run_ppo
    ray.init(
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/lib/python3.11/site-packages/ray/_private/worker.py", line 1579, in init
    ctx = builder.connect()
          ^^^^^^^^^^^^^^^^^
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/lib/python3.11/site-packages/ray/client_builder.py", line 175, in connect
    client_info_dict = ray.util.client_connect.connect(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/lib/python3.11/site-packages/ray/util/client_connect.py", line 55, in connect
    conn = ray.connect(
           ^^^^^^^^^^^^
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/lib/python3.11/site-packages/ray/util/client/__init__.py", line 233, in connect
    conn = self.get_context().connect(*args, **kw_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/lib/python3.11/site-packages/ray/util/client/__init__.py", line 97, in connect
    self.client_worker._server_init(job_config, ray_init_kwargs)
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/lib/python3.11/site-packages/ray/util/client/worker.py", line 860, in _server_init
    raise ConnectionAbortedError(
ConnectionAbortedError: Initialization failure from server:
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/util/client/server/proxier.py", line 707, in Datapath
    if not self.proxy_manager.start_specific_server(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/util/client/server/proxier.py", line 307, in start_specific_server
    serialized_runtime_env_context = self._create_runtime_env(
  File "/home/bingxing2/ailab/wangkuncan/.local/lib/python3.10/site-packages/ray/util/client/server/proxier.py", line 283, in _create_runtime_env
    raise TimeoutError(
TimeoutError: GetOrCreateRuntimeEnv request failed after 5 attempts. Last exception: HTTP Error 503: Service Unavailable


Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
