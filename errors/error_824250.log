+ export VLLM_ATTENTION_BACKEND=XFORMERS
+ VLLM_ATTENTION_BACKEND=XFORMERS
++ pwd
+ export PYTHONPATH=/home/bingxing2/ailab/wangkuncan/soft/l1/scripts/train/../../verl/
+ PYTHONPATH=/home/bingxing2/ailab/wangkuncan/soft/l1/scripts/train/../../verl/
+ export PATH=/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/bin:/home/bingxing2/apps/compilers/cuda/cuda-12.4/bin:/home/bingxing2/ailab/wangkuncan/.vscode-server/bin/f1b07bd25dfad64b0167beb15359ae573aecd2cc/bin/remote-cli:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/apps/compilers/gcc/11.3.0/bin:/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/bin:/home/bingxing2/apps/miniforge3/24.1.2/condabin:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/apps/tools/modules/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/ailab/wangkuncan/.vscode-server/bin/f1b07bd25dfad64b0167beb15359ae573aecd2cc/bin/remote-cli:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/apps/compilers/gcc/11.3.0/bin:/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/bin:/home/bingxing2/apps/miniforge3/24.1.2/condabin:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/apps/tools/modules/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/home/bingxing2/ailab/wangkuncan/.vscode-server/bin/f1b07bd25dfad64b0167beb15359ae573aecd2cc/bin/remote-cli:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/apps/compilers/gcc/11.3.0/bin:/home/bingxing2/apps/miniforge3/24.1.2/bin:/home/bingxing2/apps/miniforge3/24.1.2/condabin:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/apps/tools/modules/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
+ PATH=/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/bin:/home/bingxing2/apps/compilers/cuda/cuda-12.4/bin:/home/bingxing2/ailab/wangkuncan/.vscode-server/bin/f1b07bd25dfad64b0167beb15359ae573aecd2cc/bin/remote-cli:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/apps/compilers/gcc/11.3.0/bin:/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/bin:/home/bingxing2/apps/miniforge3/24.1.2/condabin:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/apps/tools/modules/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/ailab/wangkuncan/.vscode-server/bin/f1b07bd25dfad64b0167beb15359ae573aecd2cc/bin/remote-cli:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/apps/compilers/gcc/11.3.0/bin:/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/bin:/home/bingxing2/apps/miniforge3/24.1.2/condabin:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/apps/tools/modules/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/home/bingxing2/ailab/wangkuncan/.vscode-server/bin/f1b07bd25dfad64b0167beb15359ae573aecd2cc/bin/remote-cli:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/apps/compilers/gcc/11.3.0/bin:/home/bingxing2/apps/miniforge3/24.1.2/bin:/home/bingxing2/apps/miniforge3/24.1.2/condabin:/home/bingxing2/ailab/wangkuncan/.local/bin:/home/bingxing2/ailab/wangkuncan/bin:/home/bingxing2/apps/tools/modules/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
+ unset http_proxy
+ unset https_proxy
+ [[ 0 -gt 0 ]]
+ '[' -z '' ']'
+ MODEL_PATH=/home/bingxing2/ailab/wangkuncan/soft/l1/DeepScaleR-1.5B-Preview
+ ray stop
+ ray start --head --port=6379 --disable-usage-stats
+ unset RAY_ADDRESS
+ sleep 15
+ python3 -m verl.trainer.main_ppo --config-name=ppo_trainer.yaml algorithm.adv_estimator=grpo data.train_files=/home/bingxing2/ailab/wangkuncan/deepscaler/data/mmlu_1000.parquet data.val_files=/home/bingxing2/ailab/wangkuncan/deepscaler/data/mmlu_1000.parquet data.train_batch_size=128 data.val_batch_size=512 data.max_prompt_length=1024 data.max_response_length=4096 actor_rollout_ref.model.path=/home/bingxing2/ailab/wangkuncan/soft/l1/DeepScaleR-1.5B-Preview actor_rollout_ref.model.lora_rank=8 actor_rollout_ref.model.lora_alpha=16 'actor_rollout_ref.model.target_modules=[k_proj,v_proj]' actor_rollout_ref.actor.optim.lr=1e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=64 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.ppo_max_token_len_per_gpu=32768 actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0.001 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.ulysses_sequence_parallel_size=1 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=True actor_rollout_ref.rollout.tensor_model_parallel_size=2 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.temperature=0.6 actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=16 actor_rollout_ref.ref.fsdp_config.param_offload=True algorithm.kl_ctrl.kl_coef=0.001 trainer.critic_warmup=0 'trainer.logger=[console]' trainer.project_name=deepscaler trainer.experiment_name=l1_exact trainer.val_before_train=True trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.save_freq=20 trainer.test_freq=20 trainer.default_hdfs_dir=null trainer.total_epochs=3
2025-05-29 17:15:49,856	INFO worker.py:1694 -- Connecting to existing Ray cluster at address: 173.3.219.114:6379...
2025-05-29 17:15:49,866	INFO worker.py:1879 -- Connected to Ray cluster. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
[36m(TaskRunner pid=2075652)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2075652)[0m WARNING:2025-05-29 17:16:12,325:Waiting for register center actor 5j84SS_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(TaskRunner pid=2075652)[0m WARNING:2025-05-29 17:16:42,345:Waiting for register center actor 5j84SS_register_center to be ready. Elapsed time: 30 seconds out of 300 seconds.
[36m(TaskRunner pid=2075652)[0m WARNING:2025-05-29 17:17:12,362:Waiting for register center actor 5j84SS_register_center to be ready. Elapsed time: 60 seconds out of 300 seconds.
[36m(TaskRunner pid=2075652)[0m WARNING:2025-05-29 17:17:42,379:Waiting for register center actor 5j84SS_register_center to be ready. Elapsed time: 90 seconds out of 300 seconds.
[36m(TaskRunner pid=2075652)[0m WARNING:2025-05-29 17:18:12,396:Waiting for register center actor 5j84SS_register_center to be ready. Elapsed time: 120 seconds out of 300 seconds.
[36m(TaskRunner pid=2075652)[0m WARNING:2025-05-29 17:18:42,413:Waiting for register center actor 5j84SS_register_center to be ready. Elapsed time: 150 seconds out of 300 seconds.
[36m(TaskRunner pid=2075652)[0m WARNING:2025-05-29 17:19:12,430:Waiting for register center actor 5j84SS_register_center to be ready. Elapsed time: 180 seconds out of 300 seconds.
[36m(TaskRunner pid=2075652)[0m WARNING:2025-05-29 17:19:42,447:Waiting for register center actor 5j84SS_register_center to be ready. Elapsed time: 210 seconds out of 300 seconds.
[36m(TaskRunner pid=2075652)[0m WARNING:2025-05-29 17:20:12,464:Waiting for register center actor 5j84SS_register_center to be ready. Elapsed time: 240 seconds out of 300 seconds.
[36m(TaskRunner pid=2075652)[0m WARNING:2025-05-29 17:20:42,480:Waiting for register center actor 5j84SS_register_center to be ready. Elapsed time: 270 seconds out of 300 seconds.
Error executing job with overrides: ['algorithm.adv_estimator=grpo', 'data.train_files=/home/bingxing2/ailab/wangkuncan/deepscaler/data/mmlu_1000.parquet', 'data.val_files=/home/bingxing2/ailab/wangkuncan/deepscaler/data/mmlu_1000.parquet', 'data.train_batch_size=128', 'data.val_batch_size=512', 'data.max_prompt_length=1024', 'data.max_response_length=4096', 'actor_rollout_ref.model.path=/home/bingxing2/ailab/wangkuncan/soft/l1/DeepScaleR-1.5B-Preview', 'actor_rollout_ref.model.lora_rank=8', 'actor_rollout_ref.model.lora_alpha=16', 'actor_rollout_ref.model.target_modules=[k_proj,v_proj]', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=64', 'actor_rollout_ref.actor.use_dynamic_bsz=True', 'actor_rollout_ref.actor.ppo_max_token_len_per_gpu=32768', 'actor_rollout_ref.actor.use_kl_loss=True', 'actor_rollout_ref.actor.kl_loss_coef=0.001', 'actor_rollout_ref.actor.kl_loss_type=low_var_kl', 'actor_rollout_ref.actor.ulysses_sequence_parallel_size=1', 'actor_rollout_ref.model.enable_gradient_checkpointing=True', 'actor_rollout_ref.actor.fsdp_config.param_offload=False', 'actor_rollout_ref.actor.fsdp_config.optimizer_offload=True', 'actor_rollout_ref.rollout.tensor_model_parallel_size=2', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.temperature=0.6', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.8', 'actor_rollout_ref.rollout.n=16', 'actor_rollout_ref.ref.fsdp_config.param_offload=True', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.critic_warmup=0', 'trainer.logger=[console]', 'trainer.project_name=deepscaler', 'trainer.experiment_name=l1_exact', 'trainer.val_before_train=True', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=20', 'trainer.test_freq=20', 'trainer.default_hdfs_dir=null', 'trainer.total_epochs=3']
Traceback (most recent call last):
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_ppo.py", line 64, in main
    run_ppo(config)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_ppo.py", line 77, in run_ppo
    ray.get(runner.run.remote(config))
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/lib/python3.11/site-packages/ray/_private/worker.py", line 2822, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bingxing2/ailab/wangkuncan/.conda/envs/L1-new/lib/python3.11/site-packages/ray/_private/worker.py", line 930, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TimeoutError): [36mray::TaskRunner.run()[39m (pid=2075652, ip=173.3.219.114, actor_id=d7dfb85bff1a56edcf1371f601000000, repr=<main_ppo.TaskRunner object at 0x4001434759d0>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/main_ppo.py", line 191, in run
    trainer.init_workers()
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/trainer/ppo/ray_trainer.py", line 733, in init_workers
    wg_dict = self.ray_worker_group_cls(resource_pool=resource_pool, ray_cls_with_init=worker_dict_cls, device_name=self.device_name, **wg_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/single_controller/ray/base.py", line 269, in __init__
    self._init_with_resource_pool(resource_pool=resource_pool, ray_cls_with_init=ray_cls_with_init, bin_pack=bin_pack, detached=detached)
  File "/home/bingxing2/ailab/wangkuncan/soft/l1/verl/verl/single_controller/ray/base.py", line 376, in _init_with_resource_pool
    raise TimeoutError(
TimeoutError: Failed to get register_center_actor 5j84SS_register_center in [] for 300 seconds. Ensure that any lingering Ray resources from previous runs are cleaned up (e.g., by restarting the Ray cluster), or adjust the waiting time by modifying the config `trainer.ray_wait_register_center_timeout`.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
